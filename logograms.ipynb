{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "logograms.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhanhPham2411/how_to_generate_video/blob/master/logograms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImwWjYF6OtS8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "cd84a910-4526-4c46-8406-2f3b236eb428"
      },
      "source": [
        "!wget https://github.com/llSourcell/how_to_generate_video/archive/edef78f0f58e2160b4e047de373795b4167026ee.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-30 15:45:03--  https://github.com/llSourcell/how_to_generate_video/archive/edef78f0f58e2160b4e047de373795b4167026ee.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/llSourcell/how_to_generate_video/zip/edef78f0f58e2160b4e047de373795b4167026ee [following]\n",
            "--2020-05-30 15:45:04--  https://codeload.github.com/llSourcell/how_to_generate_video/zip/edef78f0f58e2160b4e047de373795b4167026ee\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘edef78f0f58e2160b4e047de373795b4167026ee.zip’\n",
            "\n",
            "edef78f0f58e2160b4e     [       <=>          ]  12.67M  6.02MB/s    in 2.1s    \n",
            "\n",
            "2020-05-30 15:45:07 (6.02 MB/s) - ‘edef78f0f58e2160b4e047de373795b4167026ee.zip’ saved [13286207]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1302zMIYOtya",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3cf2ad69-0ecb-4d8b-eff8-6dd146ed1a83"
      },
      "source": [
        "!unzip edef78f0f58e2160b4e047de373795b4167026ee.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  edef78f0f58e2160b4e047de373795b4167026ee.zip\n",
            "edef78f0f58e2160b4e047de373795b4167026ee\n",
            "   creating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/\n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/.gitignore  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/README.md  \n",
            "   creating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/examples/\n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/examples/clean.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/examples/clean1.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/examples/clean2.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/examples/dirty.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/examples/dirty1.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/examples/dirty2.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/generated_image.png  \n",
            "   creating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/\n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/0_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/100_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/10_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/110_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/120_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/130_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/140_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/150_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/160_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/170_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/180_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/190_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/200_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/20_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/210_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/220_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/230_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/240_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/250_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/260_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/270_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/280_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/290_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/300_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/30_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/310_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/320_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/330_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/340_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/350_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/360_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/370_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/380_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/390_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/40_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/50_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/60_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/70_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/80_0.png  \n",
            " extracting: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logo-generated-images/90_0.png  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logograms.ipynb  \n",
            "   creating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/\n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/AbbotIsDead1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/Abbott1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/AbbottChoosesSaveLouiseIan1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/BeforeAndAfter1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/Costello1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/CowrittenLogogram1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/Earth1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/HepPurpEarth_1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/HepReply1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/HepWritesRealTime1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/Heptapod1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/Human1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/Human_1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/Humanity1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/Ian1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/IanLouiseEatApple1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/IanLouiseMustGo1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/ItWasntUs1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/Louise1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/LouiseHasQuestion1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/LouiseHasWeapon1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/LouiseWritesHepto1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/MessageHereLouiseHasWeapon1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/MustLearnIanLouise1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/OfferWeapon1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/OfferWeapon_1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/SendHeptaMessage1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/ShipGrounded_1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/Solve1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/SolveOnYouNow1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/ThereIsNoLinearTime1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/Time1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/UseMarkerWrite1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/Walk1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/Weapon1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/WeaponToolDuality1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/WhereIsAbbott1.jpg  \n",
            "  inflating: how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee/logos/YouHaveChooseLife1.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z_7E8K0OvJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bfc01ea8-f30d-4071-92e2-a2790cc7b8da"
      },
      "source": [
        "cd how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ULEYPgG2Orjm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b64c9053-dae8-49c5-f035-17e6e4e55866"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "# https://stackoverflow.com/questions/57797113/attributeerror-module-keras-backend-has-no-attribute-image-dim-ordering\n",
        "# image_dim_ordering change to image_data_format from Keras 2.x\n",
        "# K.set_image_dim_ordering('th') # ensure our dimension notation matches\n",
        "# https://github.com/keras-team/keras/issues/12649#issuecomment-615132968\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Reshape\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.convolutional import Convolution2D, AveragePooling2D\n",
        "from keras.layers.core import Flatten\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.datasets import mnist\n",
        "from keras import utils\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "import argparse\n",
        "import math\n",
        "\n",
        "import os\n",
        "import os.path\n",
        "\n",
        "import glob"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skjA-mGmRGv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "060278af-3439-457a-d6cd-2342f6d7c544"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import keras.backend.tensorflow_backend as tfback\n",
        "\n",
        "print(\"tf.__version__ is\", tf.__version__)\n",
        "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
        "\n",
        "def _get_available_gpus():\n",
        "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
        "\n",
        "    # Returns\n",
        "        A list of available GPU devices.\n",
        "    \"\"\"\n",
        "    #global _LOCAL_DEVICES\n",
        "    if tfback._LOCAL_DEVICES is None:\n",
        "        devices = tf.config.list_logical_devices()\n",
        "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
        "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
        "\n",
        "tfback._get_available_gpus = _get_available_gpus"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.__version__ is 2.2.0\n",
            "tf.keras.__version__ is: 2.3.0-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "9FVmGybpOrj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(input_dim=100, output_dim=1024))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(Dense(128*8*8))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(Reshape((128, 8, 8), input_shape=(128*8*8,)))\n",
        "    model.add(UpSampling2D(size=(4, 4)))\n",
        "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(UpSampling2D(size=(4, 4)))\n",
        "    model.add(Convolution2D(1, 5, 5, border_mode='same'))\n",
        "    model.add(Activation('tanh'))\n",
        "    return model\n",
        "\n",
        "\n",
        "def discriminator_model():\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(\n",
        "                        64, 5, 5,\n",
        "                        border_mode='same',\n",
        "                        input_shape=(1, 128, 128)))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(AveragePooling2D(pool_size=(4, 4)))\n",
        "    model.add(Convolution2D(128, 5, 5))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    return model\n",
        "\n",
        "\n",
        "def generator_containing_discriminator(generator, discriminator):\n",
        "    model = Sequential()\n",
        "    model.add(generator)\n",
        "    discriminator.trainable = False\n",
        "    model.add(discriminator)\n",
        "    return model\n",
        "\n",
        "\n",
        "def combine_images(generated_images):\n",
        "    num = generated_images.shape[0]\n",
        "    width = int(math.sqrt(num))\n",
        "    height = int(math.ceil(float(num)/width))\n",
        "    shape = generated_images.shape[2:]\n",
        "    image = np.zeros((height*shape[0], width*shape[1]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
        "            img[0, :, :]\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "JrUB9sIJOrj_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "00bbda62-554b-406d-cf25-6a77296a050f"
      },
      "source": [
        "model = generator_model()\n",
        "print(model.summary())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 1024)              103424    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 8192)              8396800   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8192)              32768     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 128, 8, 8)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 128, 32, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 64, 32, 32)        204864    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 64, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 64, 128, 128)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 1, 128, 128)       1601      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 1, 128, 128)       0         \n",
            "=================================================================\n",
            "Total params: 8,739,457\n",
            "Trainable params: 8,723,073\n",
            "Non-trainable params: 16,384\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=100, units=1024)`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), padding=\"same\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (5, 5), padding=\"same\")`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "a_IN0rKEOrkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(pixels=128, verbose=False):\n",
        "    print(\"Loading data\")\n",
        "    X_train = []\n",
        "    paths = glob.glob(os.path.normpath(os.getcwd() + '/logos/*.jpg'))\n",
        "    for path in paths:\n",
        "        if verbose: print(path)\n",
        "        im = Image.open(path)\n",
        "        im = ImageOps.fit(im, (pixels, pixels), Image.ANTIALIAS)\n",
        "        im = ImageOps.grayscale(im)\n",
        "        #im.show()\n",
        "        im = np.asarray(im)\n",
        "        X_train.append(im)\n",
        "    print(\"Finished loading data\")\n",
        "    return np.array(X_train)\n",
        "\n",
        "def train(epochs, BATCH_SIZE, weights=False):\n",
        "    \"\"\"\n",
        "    :param epochs: Train for this many epochs\n",
        "    :param BATCH_SIZE: Size of minibatch\n",
        "    :param weights: If True, load weights from file, otherwise train the model from scratch. \n",
        "    Use this if you have already saved state of the network and want to train it further.\n",
        "    \"\"\"\n",
        "    X_train = load_data()\n",
        "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
        "    X_train = X_train.reshape((X_train.shape[0], 1) + X_train.shape[1:])\n",
        "    discriminator = discriminator_model()\n",
        "    generator = generator_model()\n",
        "    if weights:\n",
        "        generator.load_weights('goodgenerator.h5')\n",
        "        discriminator.load_weights('gooddiscriminator.h5')\n",
        "    discriminator_on_generator = \\\n",
        "        generator_containing_discriminator(generator, discriminator)\n",
        "    d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "    g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "    generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
        "    discriminator_on_generator.compile(\n",
        "        loss='binary_crossentropy', optimizer=g_optim)\n",
        "    discriminator.trainable = True\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
        "    noise = np.zeros((BATCH_SIZE, 100))\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch is\", epoch)\n",
        "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
        "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
        "            for i in range(BATCH_SIZE):\n",
        "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
        "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
        "            generated_images = generator.predict(noise, verbose=0)\n",
        "            #print(generated_images.shape)\n",
        "            if index % 20 == 0 and epoch % 10 == 0:\n",
        "                image = combine_images(generated_images)\n",
        "                image = image*127.5+127.5\n",
        "                destpath = os.path.normpath(os.getcwd()+ \"/logo-generated-images/\"+str(epoch)+\"_\"+str(index)+\".png\")\n",
        "                Image.fromarray(image.astype(np.uint8)).save(destpath)\n",
        "            X = np.concatenate((image_batch, generated_images))\n",
        "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
        "            d_loss = discriminator.train_on_batch(X, y)\n",
        "            print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
        "            for i in range(BATCH_SIZE):\n",
        "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
        "            discriminator.trainable = False\n",
        "            g_loss = discriminator_on_generator.train_on_batch(\n",
        "                noise, [1] * BATCH_SIZE)\n",
        "            discriminator.trainable = True\n",
        "            print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
        "            if epoch % 10 == 9:\n",
        "                generator.save_weights('goodgenerator.h5', True)\n",
        "                discriminator.save_weights('gooddiscriminator.h5', True)\n",
        "\n",
        "def clean(image):\n",
        "    for i in range(1, image.shape[0] - 1):\n",
        "        for j in range(1, image.shape[1] - 1):\n",
        "            if image[i][j] + image[i+1][j] + image[i][j+1] + image[i-1][j] + image[i][j-1] > 127 * 5:\n",
        "                image[i][j] = 255\n",
        "    return image\n",
        "def generate(BATCH_SIZE):\n",
        "    generator = generator_model()\n",
        "    generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
        "    generator.load_weights('goodgenerator.h5')\n",
        "    noise = np.zeros((BATCH_SIZE, 100))\n",
        "    a = np.random.uniform(-1, 1, 100)\n",
        "    b = np.random.uniform(-1, 1, 100)\n",
        "    grad = (b - a) / BATCH_SIZE\n",
        "    for i in range(BATCH_SIZE):\n",
        "        noise[i, :] = np.random.uniform(-1, 1, 100)\n",
        "    generated_images = generator.predict(noise, verbose=1)\n",
        "    #image = combine_images(generated_images)\n",
        "    print(generated_images.shape)\n",
        "    for image in generated_images:\n",
        "        image = image[0]\n",
        "        image = image*127.5+127.5\n",
        "        Image.fromarray(image.astype(np.uint8)).save(\"dirty.png\")\n",
        "        Image.fromarray(image.astype(np.uint8)).show()\n",
        "        clean(image)\n",
        "        image = Image.fromarray(image.astype(np.uint8))\n",
        "        image.show()        \n",
        "        image.save(\"clean.png\")\n",
        "\n",
        "\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--mode\", type=str)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=128)\n",
        "    parser.add_argument(\"--nice\", dest=\"nice\", action=\"store_true\")\n",
        "    parser.set_defaults(nice=False)\n",
        "    args = parser.parse_args()\n",
        "    return args\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "0k8TmQM6OrkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(400, 10, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "scrolled": false,
        "id": "hhfsXwPAOrkP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "1fa56543-e0dd-4329-c80d-17ce0166572f"
      },
      "source": [
        "generate(1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 0s 27ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=100, units=1024)`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), padding=\"same\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (5, 5), padding=\"same\")`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1, 1, 128, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "viLdOrdEOrkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}