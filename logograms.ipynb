{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "logograms.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhanhPham2411/how_to_generate_video/blob/master/logograms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImwWjYF6OtS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/llSourcell/how_to_generate_video/archive/edef78f0f58e2160b4e047de373795b4167026ee.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1302zMIYOtya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip edef78f0f58e2160b4e047de373795b4167026ee.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z_7E8K0OvJG",
        "colab_type": "code",
        "outputId": "bfc01ea8-f30d-4071-92e2-a2790cc7b8da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/how_to_generate_video-edef78f0f58e2160b4e047de373795b4167026ee\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ULEYPgG2Orjm",
        "colab_type": "code",
        "outputId": "b64c9053-dae8-49c5-f035-17e6e4e55866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "# https://stackoverflow.com/questions/57797113/attributeerror-module-keras-backend-has-no-attribute-image-dim-ordering\n",
        "# image_dim_ordering change to image_data_format from Keras 2.x\n",
        "# K.set_image_dim_ordering('th') # ensure our dimension notation matches\n",
        "# https://github.com/keras-team/keras/issues/12649#issuecomment-615132968\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Reshape\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.convolutional import Convolution2D, AveragePooling2D\n",
        "from keras.layers.core import Flatten\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.datasets import mnist\n",
        "from keras import utils\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "import argparse\n",
        "import math\n",
        "\n",
        "import os\n",
        "import os.path\n",
        "\n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skjA-mGmRGv0",
        "colab_type": "code",
        "outputId": "060278af-3439-457a-d6cd-2342f6d7c544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# https://github.com/keras-team/keras/issues/13684#issuecomment-595054461 - experimental_list_devices in tensorflow_backend.py\n",
        "import tensorflow as tf\n",
        "import keras.backend.tensorflow_backend as tfback\n",
        "\n",
        "print(\"tf.__version__ is\", tf.__version__)\n",
        "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
        "\n",
        "def _get_available_gpus():\n",
        "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
        "\n",
        "    # Returns\n",
        "        A list of available GPU devices.\n",
        "    \"\"\"\n",
        "    #global _LOCAL_DEVICES\n",
        "    if tfback._LOCAL_DEVICES is None:\n",
        "        devices = tf.config.list_logical_devices()\n",
        "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
        "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
        "\n",
        "tfback._get_available_gpus = _get_available_gpus"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.__version__ is 2.2.0\n",
            "tf.keras.__version__ is: 2.3.0-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "9FVmGybpOrj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(input_dim=100, output_dim=1024))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(Dense(128*8*8))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(Reshape((128, 8, 8), input_shape=(128*8*8,)))\n",
        "    model.add(UpSampling2D(size=(4, 4)))\n",
        "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(UpSampling2D(size=(4, 4)))\n",
        "    model.add(Convolution2D(1, 5, 5, border_mode='same'))\n",
        "    model.add(Activation('tanh'))\n",
        "    return model\n",
        "\n",
        "\n",
        "def discriminator_model():\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(\n",
        "                        64, 5, 5,\n",
        "                        border_mode='same',\n",
        "                        input_shape=(1, 128, 128)))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(AveragePooling2D(pool_size=(4, 4)))\n",
        "    model.add(Convolution2D(128, 5, 5))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    return model\n",
        "\n",
        "\n",
        "def generator_containing_discriminator(generator, discriminator):\n",
        "    model = Sequential()\n",
        "    model.add(generator)\n",
        "    discriminator.trainable = False\n",
        "    model.add(discriminator)\n",
        "    return model\n",
        "\n",
        "\n",
        "def combine_images(generated_images):\n",
        "    num = generated_images.shape[0]\n",
        "    width = int(math.sqrt(num))\n",
        "    height = int(math.ceil(float(num)/width))\n",
        "    shape = generated_images.shape[2:]\n",
        "    image = np.zeros((height*shape[0], width*shape[1]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
        "            img[0, :, :]\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "JrUB9sIJOrj_",
        "colab_type": "code",
        "outputId": "00bbda62-554b-406d-cf25-6a77296a050f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "model = generator_model()\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 1024)              103424    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 8192)              8396800   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8192)              32768     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 128, 8, 8)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 128, 32, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 64, 32, 32)        204864    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 64, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 64, 128, 128)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 1, 128, 128)       1601      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 1, 128, 128)       0         \n",
            "=================================================================\n",
            "Total params: 8,739,457\n",
            "Trainable params: 8,723,073\n",
            "Non-trainable params: 16,384\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=100, units=1024)`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), padding=\"same\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (5, 5), padding=\"same\")`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "a_IN0rKEOrkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(pixels=128, verbose=False):\n",
        "    print(\"Loading data\")\n",
        "    X_train = []\n",
        "    paths = glob.glob(os.path.normpath(os.getcwd() + '/logos/*.jpg'))\n",
        "    for path in paths:\n",
        "        if verbose: print(path)\n",
        "        im = Image.open(path)\n",
        "        im = ImageOps.fit(im, (pixels, pixels), Image.ANTIALIAS)\n",
        "        im = ImageOps.grayscale(im)\n",
        "        #im.show()\n",
        "        im = np.asarray(im)\n",
        "        X_train.append(im)\n",
        "    print(\"Finished loading data\")\n",
        "    return np.array(X_train)\n",
        "\n",
        "def train(epochs, BATCH_SIZE, weights=False):\n",
        "    \"\"\"\n",
        "    :param epochs: Train for this many epochs\n",
        "    :param BATCH_SIZE: Size of minibatch\n",
        "    :param weights: If True, load weights from file, otherwise train the model from scratch. \n",
        "    Use this if you have already saved state of the network and want to train it further.\n",
        "    \"\"\"\n",
        "    X_train = load_data()\n",
        "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
        "    X_train = X_train.reshape((X_train.shape[0], 1) + X_train.shape[1:])\n",
        "    discriminator = discriminator_model()\n",
        "    generator = generator_model()\n",
        "    if weights:\n",
        "        generator.load_weights('goodgenerator.h5')\n",
        "        discriminator.load_weights('gooddiscriminator.h5')\n",
        "    discriminator_on_generator = \\\n",
        "        generator_containing_discriminator(generator, discriminator)\n",
        "    d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "    g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "    generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
        "    discriminator_on_generator.compile(\n",
        "        loss='binary_crossentropy', optimizer=g_optim)\n",
        "    discriminator.trainable = True\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
        "    noise = np.zeros((BATCH_SIZE, 100))\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch is\", epoch)\n",
        "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
        "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
        "            for i in range(BATCH_SIZE):\n",
        "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
        "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
        "            generated_images = generator.predict(noise, verbose=0)\n",
        "            #print(generated_images.shape)\n",
        "            if index % 20 == 0 and epoch % 10 == 0:\n",
        "                image = combine_images(generated_images)\n",
        "                image = image*127.5+127.5\n",
        "                destpath = os.path.normpath(os.getcwd()+ \"/logo-generated-images/\"+str(epoch)+\"_\"+str(index)+\".png\")\n",
        "                Image.fromarray(image.astype(np.uint8)).save(destpath)\n",
        "            X = np.concatenate((image_batch, generated_images))\n",
        "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
        "            d_loss = discriminator.train_on_batch(X, y)\n",
        "            print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
        "            for i in range(BATCH_SIZE):\n",
        "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
        "            discriminator.trainable = False\n",
        "            g_loss = discriminator_on_generator.train_on_batch(\n",
        "                noise, [1] * BATCH_SIZE)\n",
        "            discriminator.trainable = True\n",
        "            print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
        "            if epoch % 10 == 9:\n",
        "                generator.save_weights('goodgenerator.h5', True)\n",
        "                discriminator.save_weights('gooddiscriminator.h5', True)\n",
        "\n",
        "def clean(image):\n",
        "    for i in range(1, image.shape[0] - 1):\n",
        "        for j in range(1, image.shape[1] - 1):\n",
        "            if image[i][j] + image[i+1][j] + image[i][j+1] + image[i-1][j] + image[i][j-1] > 127 * 5:\n",
        "                image[i][j] = 255\n",
        "    return image\n",
        "def generate(BATCH_SIZE):\n",
        "    generator = generator_model()\n",
        "    generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
        "    generator.load_weights('goodgenerator.h5')\n",
        "    noise = np.zeros((BATCH_SIZE, 100))\n",
        "    a = np.random.uniform(-1, 1, 100)\n",
        "    b = np.random.uniform(-1, 1, 100)\n",
        "    grad = (b - a) / BATCH_SIZE\n",
        "    for i in range(BATCH_SIZE):\n",
        "        noise[i, :] = np.random.uniform(-1, 1, 100)\n",
        "    generated_images = generator.predict(noise, verbose=1)\n",
        "    #image = combine_images(generated_images)\n",
        "    print(generated_images.shape)\n",
        "    for image in generated_images:\n",
        "        image = image[0]\n",
        "        image = image*127.5+127.5\n",
        "        Image.fromarray(image.astype(np.uint8)).save(\"dirty.png\")\n",
        "        Image.fromarray(image.astype(np.uint8)).show()\n",
        "        clean(image)\n",
        "        image = Image.fromarray(image.astype(np.uint8))\n",
        "        image.show()        \n",
        "        image.save(\"clean.png\")\n",
        "\n",
        "\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--mode\", type=str)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=128)\n",
        "    parser.add_argument(\"--nice\", dest=\"nice\", action=\"store_true\")\n",
        "    parser.set_defaults(nice=False)\n",
        "    args = parser.parse_args()\n",
        "    return args\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "0k8TmQM6OrkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(400, 10, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "scrolled": false,
        "id": "hhfsXwPAOrkP",
        "colab_type": "code",
        "outputId": "1fa56543-e0dd-4329-c80d-17ce0166572f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "generate(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 0s 27ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=100, units=1024)`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), padding=\"same\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (5, 5), padding=\"same\")`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1, 1, 128, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "viLdOrdEOrkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}